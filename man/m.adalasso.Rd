% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/m.adalasso.R
\name{m.adalasso}
\alias{m.adalasso}
\title{Adaptive Lasso for tidyfit}
\usage{
m.adalasso(x, y, lambda = NULL, ...)
}
\arguments{
\item{x}{input matrix or data.frame, of dimension \eqn{(N\times p)}{(N x p)}; each row is an observation vector.}

\item{y}{response variable.}

\item{lambda}{shrinkage parameter or vector of shrinkage parameters.}

\item{...}{Additional arguments passed to \code{glmnet::glmnet}.}
}
\value{
A 'tibble'.
}
\description{
Fits an adaptive Lasso regression and returns the results as a tibble. The function can be used with \code{tidyfit}.
}
\details{
The adaptive Lasso is a weighted implementation of the Lasso algorithm, with covariate-specific weights obtained using an initial regression fit (in this case, a ridge regression with \code{lambda = 0.01}). The adaptive Lasso is computed using the 'glmnet' package.

The function can be used for classification or regression, covariates are standardized and an intercept is always included.
}
\examples{
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = m.adalasso(x, y, lambda = 0.1)

}
\references{
Zou, H. (2006).
The Adaptive Lasso and Its Oracle Properties.
Journal of the American Statistical Association, 101(476), 1418-1429.

Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010).
Regularization Paths for Generalized Linear Models via Coordinate Descent.
Journal of Statistical Software, 33(1), 1-22. URL https://www.jstatsoft.org/v33/i01/.
}
\seealso{
\code{tidypredict} method
}
\author{
Johann Pfitzinger
}
