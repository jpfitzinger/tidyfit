% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/m.R
\name{m}
\alias{m}
\title{Generic model wrapper for \code{tidyfit}}
\usage{
m(
  model_method,
  x = NULL,
  y = NULL,
  ...,
  .remove_dependent_features = TRUE,
  .return_method_name = FALSE,
  .check_family = FALSE
)
}
\arguments{
\item{model_method}{The name of the method to fit. See Details.}

\item{x}{Input matrix or data.frame, of dimension \eqn{(N\times p)}{(N x p)}; each row is an observation vector.}

\item{y}{Response variable.}

\item{...}{Additional arguments passed to the underlying method function (e.g. \code{lm} or \code{glm}).}

\item{.remove_dependent_features}{When \code{TRUE}, linearly dependent features are removed using \code{qr(x)}. This avoids errors in several methods such as 'subsets' orÂ´ 'lm'.}

\item{.return_method_name}{When \code{TRUE}, the function simply returns the 'method' argument.}

\item{.check_family}{When \code{TRUE}, the function returns a flag indicating whether a custom 'family' object has been passed to \code{...}.}
}
\value{
A 'tibble'.
}
\description{
The function can fit various regression or classification models and returns the results as a tibble. \code{m()} can be used in conjunction with \code{\link{regress}} and \code{\link{classify}}, or as a stand-alone function.
}
\details{
\code{model_method} specifies the model used to regress \code{y} on \code{x} and can take one of several options:
\subsection{Linear (generalized) regression or classification}{

\code{"lm"} performs an OLS regression using \code{stats::lm}. See \code{\link{.model.lm}} for details.

\code{"glm"} performs a generalized regression using \code{stats::glm}. See \code{\link{.model.glm}} for details.

\code{"robust"} performs a robust regression using \code{MASS::rlm}. See \code{\link{.model.robust}} for details.

\code{"quantile"} performs a quantile regression using \code{quantreg::rq}. See \code{\link{.model.quantile}} for details.
}

\subsection{Regression and classification with L1 and L2 penalties}{

\code{"lasso"} performs a linear regression or classification with L1 penalty using \code{glmnet::glmnet}. See \code{\link{.model.lasso}} for details.

\code{"ridge"} performs a linear regression or classification with L2 penalty using \code{glmnet::glmnet}. See \code{\link{.model.lasso}} for details.

\code{"adalasso"} performs an Adaptive Lasso regression or classification using \code{glmnet::glmnet}. See \code{\link{.model.adalasso}} for details.

\code{"enet"} performs a linear regression or classification with L1 and L2 penalties using \code{glmnet::glmnet}. See \code{\link{.model.enet}} for details.
}

\subsection{Gradient boosting}{

\code{"boost"} performs gradient boosting regression or classificaiton using \code{mboost::glmboost}. See \code{\link{.model.boost}} for details.
}

\subsection{Factor regressions}{

\code{"pcr"} performs a principal components regression using \code{pls::pcr}. See \code{\link{.model.pcr}} for details.

\code{"plsr"} performs a partial least squares regression using \code{pls::plsr}. See \code{\link{.model.plsr}} for details.

\code{"hfr"} performs a hierarchical feature regression using \code{hfr::hfr}. See \code{\link{.model.hfr}} for details.
}

\subsection{Best subset selection}{

\code{"subset"} performs a best subset regression or classification using \code{bestglm::bestglm} (wrapper for \code{leaps}). See \code{\link{.model.subset}} for details.
}

\subsection{Bayesian regression}{

\code{"bayes"} performs a Bayesian generalized regression or classification using \code{arm::bayesglm}. See \code{\link{.model.bayes}} for details.
}

\subsection{Miscellaneous}{

\code{"cor"} calculates Pearson correlation coefficients using \code{stats::cor}. See \code{\link{.model.cor}} for details.

When called without \code{x} and \code{y} arguments, the function returns a partialised version of itself that can be called with data to fit a model.
}
}
\examples{
# Stand-alone function
x <- matrix(rnorm(100 * 20), 100, 20)
y <- rbinom(100, 1, 0.5)
fit <- m("glm", x, y)
fit

# Within 'regress' function
data <- tidyfit::Factor_Industry_Returns
fit <- regress(data, Return ~ ., m("glm"), .mask = "Date")
fit

}
\seealso{
\code{\link{regress}} and \code{\link{classify}} methods
}
\author{
Johann Pfitzinger
}
