---
output: github_document
always_allow_html: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  message = FALSE, 
  warning = FALSE
)

library(tidyverse)
```

# tidyfit <img src="man/figures/logo_nobackground.png" align="right" alt="" width="120" />

<!-- badges: start -->
<!-- badges: end -->

`tidyfit` is an `R`-package that facilitates and automates linear regression and classification modeling in a tidy environment. The package includes several methods, such as Lasso, PLS and ElasticNet regressions. `tidyfit` builds on the `tidymodels` suite, but emphasizes automated modeling with a focus on the linear regression and classification coefficients, which are the primary output of `tidyfit`. The objective is to make model fitting, cross validation and model output very simple and standardized across all methods, with the necessary method-specific transformations handled in the background.

## Installation

You can install the development version of tidyfit from [GitHub](https://github.com/) with:

```{r, eval=F}
# install.packages("devtools")
devtools::install_github("jpfitzinger/tidyfit")
```

## Why use `tidyfit`?

Here are some reasons to use `tidyfit`:

  1. It provides a standardized wrapper --- `m(<method>, x, y, ...)` --- for many regression and classification techniques (see table below)
  2. All arguments can be passed individually or as grids (e.g. `m("quantile", tau = c(0.1, 0.5, 0.9))`), making scenario analysis and setting hyperparameter grids very easy
  3. Automated hyperparameter tuning with `regress` and `classify` using `rsample` as a cross validation engine
  4. Fit models on grouped tibbles (fit by group with option to tune hyperparameter within or across groups)
  5. Outputs (coefficients) are comparable across all methods
  
## Methods implemented in `tidyfit`

See `?m` for additional information:

```{r, echo = F}
library(kableExtra)
tbl <- data.frame(
  Method = c("OLS", "Generalized least squares", "Robust regression (e.g. Huber loss)", 
             "Quantile regression", "LASSO", "Ridge", "Adaptive LASSO", "ElasticNet",
             "Gradient boosting regression", "Principal components regression", "Partial least squares",
             "Hierarchical feature regression", "Best subset selection", "Bayesian regression", "Pearson correlation"),
  Name = c("lm", "glm", "robust", "quantile", "lasso", "ridge", "adalasso", "enet", "boost", "pcr", "plsr", 
           "hfr", "subset", "bayes", "cor"),
  Package = c("`stats::lm`", "`stats::glm`", "`MASS::rlm`", "`quantreg`", "`glmnet`", "`glmnet`", "`glmnet`", "`glmnet`",
              "`mboost`", "`pls`", "`pls`", "`hfr`", "`bestglm`", "`arm`", "`stats::cor`"),
  Regression = c("yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "n/a"),
  Classification = c("no", "yes", "no", "no", "yes", "yes", "yes", "yes", "yes", "no", "no", "no", "yes", "yes", "n/a")
)

kbl(tbl, align = "lcccc") %>% 
  kable_styling("striped")

```

## Example

### Fama-French factor and industry data

`tidyfit` includes a data set of financial factor returns freely available [here](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html). The data set includes monthly industry returns for 10 industries, as well as monthly factor returns for 5 factors:

```{r example}
library(tidyfit)
data <- tidyfit::Factor_Industry_Returns
```

### Fitting a linear regression

Models are fitted using `tidyfit::regress` for regression or `tidyfit::classify` for binomial classification problems. Below a linear regression is fitted using the `tidyfit::m` model wrapper, which standardizes a large number of regression and classification techniques. The date column is masked and the industry column is one-hot encoded:

```{r}
fit <- data %>% 
  regress(Return ~ ., lin_reg = m("lm"), .mask = "Date")
fit
```

Detailed model and hyperparameter information is nested and can be expanded:

```{r}
fit %>% 
  unnest(model_info)
```

Now, instead of fitting a single regression, we need to fit a regression per industry. This is achieved simply by grouping:

```{r}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., lin_reg = m("lm"), .mask = "Date")
```

Let's plot the factor loadings in a heatmap:

```{r, fig.width=10, fig.height=5, fig.align="center"}
fit %>% 
  ggplot(aes(variable, Industry)) +
  geom_tile(aes(fill = beta)) +
  scale_fill_gradient2(low = "firebrick", high = "forestgreen")
```

### Multiple arguments

One advantage of `tidyfit` is that it allows arguments to be passed to the underlying methods as vectors. For instance, fitting a robust Huber regression (using `MASS::rlm` in the background) instead of a linear regression, it is possible to compare different estimation algorithms by passing a vector of arguments:

```{r}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., robust_reg = m("robust", method = c("M", "MM")), .mask = "Date")
```

Let's examine the difference in coefficients for a single sector-regression:

```{r}
fit %>% 
  filter(Industry == "Durbl") %>% 
  unnest(model_info) %>% 
  select(Industry, variable, beta, method) %>% 
  spread(method, beta)
```

Passing multiple arguments is also useful when fitting a quantile regression (using `quantreg::rq` in the background):

```{r, fig.width=10, fig.height=5, fig.align="center"}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., quantile_reg = m("quantile", tau = c(0.1, 0.5, 0.9)), .mask = "Date")

fit %>% 
  filter(Industry == "Durbl") %>% 
  unnest(model_info) %>% 
  select(Industry, variable, beta, tau) %>% 
  mutate(tau = as.factor(tau)) %>% 
  ggplot(aes(variable, beta, color = tau)) +
  geom_point()
```


### Fitting a Lasso regression

Fitting a Lasso regression requires hyperparameter tuning for the penalty `lambda`. This can be done by passing values to `.cv` and `.cv_args`. Cross validation is performed using `rsample`. See `?rsample::vfold_cv`, `?rsample::loo_cv`, `?rsample::initial_split`, `?rsample::initial_time_split` or `?rsample::rolling_origin` to see optional arguments that can be passed to `.cv_args`. A reasonable hyperparameter grid is determined using the `dials` package, or can be passed manually.

```{r, fig.width=10, fig.height=5, fig.align="center"}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., lasso_reg = m("lasso"), .mask = "Date", 
          .cv = "vfold", .cv_args = list(v = 5))

fit %>% 
  ggplot(aes(variable, Industry)) +
  geom_tile(aes(fill = beta)) +
  scale_fill_gradient2(low = "firebrick", high = "forestgreen")
```

The results do not appear to be different from a linear regression. To compare methods, simply pass multiple models:

```{r, eval=F}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., lasso_reg = m("lasso"), lin_reg = m("lm"), .mask = "Date", 
          .cv = "vfold", .cv_args = list(v = 5))
```

Of course, a v-fold cross validation is not valid for ordered data. Instead simply set a rolling cross validation. In addition, we can pass a custom grid for `lambda` by adding the argument to `m`. Note also that it is not necessary to specify a model name:

```{r, fig.width=10, fig.height=5, fig.align="center"}
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., m("lasso", lambda = seq(0, 0.4, by = 0.05)), .mask = "Date", 
          .cv = "rolling_origin", 
          .cv_args = list(initial = 60, assess = 24, skip = 24, cumulative = FALSE))

fit %>% 
  ggplot(aes(variable, Industry)) +
  geom_tile(aes(fill = beta)) +
  scale_fill_gradient2(low = "firebrick", high = "forestgreen")
```


### Predicting with an ElasticNet classifier

Let's predict out-of-sample return probabilities:

```{r}
data_train <- data %>% 
  mutate(Return = ifelse(Return > 0, 1, 0)) %>% 
  filter(Date <= 202112)

data_test <- data %>% 
  mutate(Return = ifelse(Return > 0, 1, 0)) %>% 
  filter(Date > 202112)
```

Classification is possible with `tidyfit` using the `classify` function instead of `regress`. This passes a `family = binomial()` argument to the underlying model functions. Note that additional arguments can be specified in the model function that are passed on to the underlying estimator (in this case `glmnet::glmnet`):

```{r}
fit <- data_train %>% 
  mutate(Return = ifelse(Return > 0, 1, 0)) %>% 
  group_by(Industry) %>% 
  classify(Return ~ ., enet_clf = m("enet", maxit = 1e+06), .mask = "Date", 
          .cv = "rolling_origin", .cv_args = list(initial = 60, assess = 24, skip = 24, cumulative = FALSE))
```

Predictions can be made for all models using `cross_prod`. As the name indicates, this generates predictions by multiplying data and coefficients (and passing through the respective link function). No model-specific predict methods are used. Predictions automatically apply along the same groups as in the fitted object, and use the response family specified during fitting:

```{r}
pred <- fit %>% 
  cross_prod(data_test) %>% 
  mutate(Predicted = ifelse(pred > 0.5, 1, 0)) %>% 
  rename(Truth = Return)

# Print a confusion matrix
table(pred$Truth, pred$Predicted)
```

### Parallel computation

`tidyfit` parallelizes cross validation computations using the `future` package in conjunction with `furrr`. Parallel computation can therefore be activated by setting an appropriate plan:

```{r, eval=F}
library(furrr)
plan(multisession(workers = 4))
fit <- data %>% 
  group_by(Industry) %>% 
  regress(Return ~ ., lasso_reg = m("lasso"), .mask = "Date", 
          .cv = "vfold", .cv_args = list(v = 5))
```


### Additional functionality

`tidyfit` makes a few things easier:

 - Methods return statistically comparable outputs. For instance, all covariates are standardized and the coefficients are back-transformed to the original scale. This is not done by all underlying packages (e.g. `pls`, which is used for the PCR and PLSR methods).
 - Hyperparameter grids are set to reasonable starting values. Custom grids can be passed to the model wrapper (e.g. `m("lasso", lambda = seq(0, 1, by = 0.1))`).
 - Hyperparameters can be tuned across all groups or separately within each group by setting the `.tune_each_group` flag.
 - Results for the individual slices can be returned using the `.return_slices` flag. This is particularly useful for rolling window estimation, which can be done by returning the results of a rolling cross validation.



